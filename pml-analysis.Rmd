---
title: "PML Prediction"
author: "Tochi Okeke"
date: "October 15, 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo =FALSE, warning = FALSE,message=FALSE)
```



```{r, echo = FALSE, results=FALSE, warning=FALSE,message=FALSE}
#Import necessary libraries
#For data manipulation
library(tidyverse) 
#For modelling pre-processing
library(caret)
#For plotting
library(ggplot2)
#For date manipulation
library(lubridate)
#For decision trees
library(tree)
#For classification trees
library(rpart)
```


Read in the datasets
```{r, echo=FALSE}
#The training set will be split into furtherparts for modelling
train <- read_csv("pml-training.csv",col_types = cols(.default="n",classe = "c", cvtd_timestamp = "c", user_name = "c", new_window = "f"))

#Leaving the test set provided as a validation set for the end of the modelling

```

Review the dataset
```{r, echo=FALSE, results=FALSE}
head(str(train))
head(summary(train))
```

Clean the dataset
```{r, echo=FALSE}
#Drop the X1 variable
train <- train %>% 
  select(-X1)

#removing all NA columns
#We have enough data so we can omit these columns

#Create a dataframe that identifies na values with TRUE/FALSE
na_check_train <- data.frame(apply(train, 2, is.na))

#Select only the columns that have no na values
na_check_train <- na_check_train %>% 
  select_if(function(col) sum(col) == 0)

#Use the column names from na_check_train to select columns without na values
train <- train %>%
  select(colnames(na_check_train))


```

Cross - Validation
-Split the train data into 2 parts using caret to train different models without overfitting

```{r,echo=FALSE}
train_splits <- createDataPartition(train$classe,2,p=.8)

train_1 <- train[train_splits$Resample1,]

test_1 <- train[-train_splits$Resample1,]

train_2 <- train[train_splits$Resample2,]

test_2 <- train[-train_splits$Resample2,]

```

## Building a decision tree

## Split 1
```{r,echo=FALSE}
train_1_tree <- rpart(classe~.,na.action = na.pass, data=train_1, method="class")

printcp(train_1_tree)

```

#Plot of the tree
```{r, echo=FALSE}

plot(train_1_tree)
text(train_1_tree)


```
#Predict using the test set
```{r, echo=FALSE}
split_1_predictions <- predict(train_1_tree,newdata = test_1)

summary(split_1_predictions)
```


The cart model had a misclassification rate of over 70%. This is not ideal, so we will try a random forest model on the second split to get improved results.

##Split 2

```{r,echo=FALSE}

#Clustering the datset to reduce the number of rows and processing time

clusters <- hclust(dist(train_2))

cut_cluster <- cutree(clusters,300)

clusters_test <- hclust(dist(test_2))

cut_cluster_test <- cutree(clusters_test,300)


#Create a column that assigns each row to a cluster
train_2$cluster <- cut_cluster
test_2$cluster <- cut_cluster_test

#Group by non-numeric variables and summarise numeric variables by their mean
train_2 <- train_2 %>%
  # select(-new_window) %>% 
  group_by(cluster,user_name,classe,cvtd_timestamp) %>% 
  summarise_all(mean) 

test_2 <- test_2 %>%
  # select(-new_window) %>% 
  group_by(cluster,user_name,classe,cvtd_timestamp) %>% 
  summarise_all(mean) 

train_2 <- train_2 %>% 
  select(-c(cluster,new_window))

test_2 <- test_2 %>% 
  select(-c(cluster,new_window))

#Build a random forest model to predict  the class variable
train_2_rf <- train(classe~.,data=train_2,method="rf")

#Predict on the test set using the random forest model
train_2_predict <- predict.train(train_2_rf,test_2)

 ```
#Out of sample error
 confusionMatrix(as.factor(test_2$classe),as.factor(train_2_predict))
 
#The error rate is .0427
#The accuracy rate is .9573


#This model has an accuracy of approximately 96% and will be the chosen model to ue on the validation set.

#Running the model on the Validation data set to get the final predictions

#We want a prediction for each of the observatiosn so there is no need to cluster.
validation <- read_csv("pml-testing.csv",col_types = cols(.default="n",classe = "c
#Apply the same cleaning process used on the training data
validation <- validation %>% ", cvtd_timestamp = "c", user_name = "c", new_window = "f") )

  select(-X1)

#Use the column names (except Classe) from na_checktrain to select columns without na values 
validation <- validation %>%
  select(colnames(na_check_train)[1:58])

#Group by non-numeric variables and summarise numeric variables by their mean
validation <- validation %>%
  group_by(user_name,cvtd_timestamp) %>% 
  summarise_all(mean) 


final_predictions <-  predict.train(train_2_rf,validation)

#Print the predictions for the 20 test cases
final_predictions
```




